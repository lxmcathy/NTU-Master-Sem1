# -*- coding: utf-8 -*-
"""Urban Computing (Indoor Localisation Project).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bTll77vY9HzTAl23U5MVyqaHV4P0LuW6

##Cloning from Github Repo
"""

# a) clone from github repo directly
!git clone https://github.com/location-competition/indoor-location-competition-20
!mv ./indoor-location-competition-20/* ./

"""##Import necessary libraries"""

import numpy as np
import scipy as copy
import dataclasses

print(np.__version__)

# install necessary packages
import sys
!pip install numpy scipy dataclasses plotly pillow

"""##Import functions"""

# this cell contain the content from io_f.py
from dataclasses import dataclass

import numpy as np


@dataclass
class ReadData:
    acce: np.ndarray
    acce_uncali: np.ndarray
    gyro: np.ndarray
    gyro_uncali: np.ndarray
    magn: np.ndarray
    magn_uncali: np.ndarray
    ahrs: np.ndarray
    wifi: np.ndarray
    ibeacon: np.ndarray
    waypoint: np.ndarray


def read_data_file(data_filename):
    acce = []
    acce_uncali = []
    gyro = []
    gyro_uncali = []
    magn = []
    magn_uncali = []
    ahrs = []
    wifi = []
    ibeacon = []
    waypoint = []

    with open(data_filename, 'r', encoding='utf-8') as file:
        lines = file.readlines()

    for line_data in lines:
        line_data = line_data.strip()
        if not line_data or line_data[0] == '#':
            continue

        line_data = line_data.split('\t')

        if line_data[1] == 'TYPE_ACCELEROMETER':
            acce.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':
            acce_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_GYROSCOPE':
            gyro.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':
            gyro_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_MAGNETIC_FIELD':
            magn.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':
            magn_uncali.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_ROTATION_VECTOR':
            ahrs.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
            continue

        if line_data[1] == 'TYPE_WIFI':
            sys_ts = line_data[0]
            ssid = line_data[2]
            bssid = line_data[3]
            rssi = line_data[4]
            lastseen_ts = line_data[6]
            wifi_data = [sys_ts, ssid, bssid, rssi, lastseen_ts]
            wifi.append(wifi_data)
            continue

        if line_data[1] == 'TYPE_BEACON':
            ts = line_data[0]
            uuid = line_data[2]
            major = line_data[3]
            minor = line_data[4]
            rssi = line_data[6]
            ibeacon_data = [ts, '_'.join([uuid, major, minor]), rssi]
            ibeacon.append(ibeacon_data)
            continue

        if line_data[1] == 'TYPE_WAYPOINT':
            waypoint.append([int(line_data[0]), float(line_data[2]), float(line_data[3])])

    acce = np.array(acce)
    acce_uncali = np.array(acce_uncali)
    gyro = np.array(gyro)
    gyro_uncali = np.array(gyro_uncali)
    magn = np.array(magn)
    magn_uncali = np.array(magn_uncali)
    ahrs = np.array(ahrs)
    wifi = np.array(wifi)
    ibeacon = np.array(ibeacon)
    waypoint = np.array(waypoint)

    return ReadData(acce, acce_uncali, gyro, gyro_uncali, magn, magn_uncali, ahrs, wifi, ibeacon, waypoint)

"""##Compute_f.py"""

import numpy as np
import scipy.signal as signal


def split_ts_seq(ts_seq, sep_ts):
    """

    :param ts_seq:
    :param sep_ts:
    :return:
    """
    tss = ts_seq[:, 0].astype(float)
    unique_sep_ts = np.unique(sep_ts)
    ts_seqs = []
    start_index = 0
    for i in range(0, unique_sep_ts.shape[0]):
        end_index = np.searchsorted(tss, unique_sep_ts[i], side='right')
        if start_index == end_index:
            continue
        ts_seqs.append(ts_seq[start_index:end_index, :].copy())
        start_index = end_index

    # tail data
    if start_index < ts_seq.shape[0]:
        ts_seqs.append(ts_seq[start_index:, :].copy())

    return ts_seqs


def correct_trajectory(original_xys, end_xy):
    """

    :param original_xys: numpy ndarray, shape(N, 2)
    :param end_xy: numpy ndarray, shape(1, 2)
    :return:
    """
    corrected_xys = np.zeros((0, 2))

    A = original_xys[0, :]
    B = end_xy
    Bp = original_xys[-1, :]

    angle_BAX = np.arctan2(B[1] - A[1], B[0] - A[0])
    angle_BpAX = np.arctan2(Bp[1] - A[1], Bp[0] - A[0])
    angle_BpAB = angle_BpAX - angle_BAX
    AB = np.sqrt(np.sum((B - A) ** 2))
    ABp = np.sqrt(np.sum((Bp - A) ** 2))

    corrected_xys = np.append(corrected_xys, [A], 0)
    for i in np.arange(1, np.size(original_xys, 0)):
        angle_CpAX = np.arctan2(original_xys[i, 1] - A[1], original_xys[i, 0] - A[0])

        angle_CAX = angle_CpAX - angle_BpAB

        ACp = np.sqrt(np.sum((original_xys[i, :] - A) ** 2))

        AC = ACp * AB / ABp

        delta_C = np.array([AC * np.cos(angle_CAX), AC * np.sin(angle_CAX)])

        C = delta_C + A

        corrected_xys = np.append(corrected_xys, [C], 0)

    return corrected_xys


def correct_positions(rel_positions, reference_positions):
    """

    :param rel_positions:
    :param reference_positions:
    :return:
    """
    rel_positions_list = split_ts_seq(rel_positions, reference_positions[:, 0])
    if len(rel_positions_list) != reference_positions.shape[0] - 1:
        # print(f'Rel positions list size: {len(rel_positions_list)}, ref positions size: {reference_positions.shape[0]}')
        del rel_positions_list[-1]
    assert len(rel_positions_list) == reference_positions.shape[0] - 1

    corrected_positions = np.zeros((0, 3))
    for i, rel_ps in enumerate(rel_positions_list):
        start_position = reference_positions[i]
        end_position = reference_positions[i + 1]
        abs_ps = np.zeros(rel_ps.shape)
        abs_ps[:, 0] = rel_ps[:, 0]
        # abs_ps[:, 1:3] = rel_ps[:, 1:3] + start_position[1:3]
        abs_ps[0, 1:3] = rel_ps[0, 1:3] + start_position[1:3]
        for j in range(1, rel_ps.shape[0]):
            abs_ps[j, 1:3] = abs_ps[j-1, 1:3] + rel_ps[j, 1:3]
        abs_ps = np.insert(abs_ps, 0, start_position, axis=0)
        corrected_xys = correct_trajectory(abs_ps[:, 1:3], end_position[1:3])
        corrected_ps = np.column_stack((abs_ps[:, 0], corrected_xys))
        if i == 0:
            corrected_positions = np.append(corrected_positions, corrected_ps, axis=0)
        else:
            corrected_positions = np.append(corrected_positions, corrected_ps[1:], axis=0)

    corrected_positions = np.array(corrected_positions)

    return corrected_positions


def init_parameters_filter(sample_freq, warmup_data, cut_off_freq=2):
    order = 4
    filter_b, filter_a = signal.butter(order, cut_off_freq / (sample_freq / 2), 'low', False)
    zf = signal.lfilter_zi(filter_b, filter_a)
    _, zf = signal.lfilter(filter_b, filter_a, warmup_data, zi=zf)
    _, filter_zf = signal.lfilter(filter_b, filter_a, warmup_data, zi=zf)

    return filter_b, filter_a, filter_zf


def get_rotation_matrix_from_vector(rotation_vector):
    q1 = rotation_vector[0]
    q2 = rotation_vector[1]
    q3 = rotation_vector[2]

    if rotation_vector.size >= 4:
        q0 = rotation_vector[3]
    else:
        q0 = 1 - q1*q1 - q2*q2 - q3*q3
        if q0 > 0:
            q0 = np.sqrt(q0)
        else:
            q0 = 0

    sq_q1 = 2 * q1 * q1
    sq_q2 = 2 * q2 * q2
    sq_q3 = 2 * q3 * q3
    q1_q2 = 2 * q1 * q2
    q3_q0 = 2 * q3 * q0
    q1_q3 = 2 * q1 * q3
    q2_q0 = 2 * q2 * q0
    q2_q3 = 2 * q2 * q3
    q1_q0 = 2 * q1 * q0

    R = np.zeros((9,))
    if R.size == 9:
        R[0] = 1 - sq_q2 - sq_q3
        R[1] = q1_q2 - q3_q0
        R[2] = q1_q3 + q2_q0

        R[3] = q1_q2 + q3_q0
        R[4] = 1 - sq_q1 - sq_q3
        R[5] = q2_q3 - q1_q0

        R[6] = q1_q3 - q2_q0
        R[7] = q2_q3 + q1_q0
        R[8] = 1 - sq_q1 - sq_q2

        R = np.reshape(R, (3, 3))
    elif R.size == 16:
        R[0] = 1 - sq_q2 - sq_q3
        R[1] = q1_q2 - q3_q0
        R[2] = q1_q3 + q2_q0
        R[3] = 0.0

        R[4] = q1_q2 + q3_q0
        R[5] = 1 - sq_q1 - sq_q3
        R[6] = q2_q3 - q1_q0
        R[7] = 0.0

        R[8] = q1_q3 - q2_q0
        R[9] = q2_q3 + q1_q0
        R[10] = 1 - sq_q1 - sq_q2
        R[11] = 0.0

        R[12] = R[13] = R[14] = 0.0
        R[15] = 1.0

        R = np.reshape(R, (4, 4))

    return R


def get_orientation(R):
    flat_R = R.flatten()
    values = np.zeros((3,))
    if np.size(flat_R) == 9:
        values[0] = np.arctan2(flat_R[1], flat_R[4])
        values[1] = np.arcsin(-flat_R[7])
        values[2] = np.arctan2(-flat_R[6], flat_R[8])
    else:
        values[0] = np.arctan2(flat_R[1], flat_R[5])
        values[1] = np.arcsin(-flat_R[9])
        values[2] = np.arctan2(-flat_R[8], flat_R[10])

    return values


def compute_steps(acce_datas):
    step_timestamps = np.array([])
    step_indexs = np.array([], dtype=int)
    step_acce_max_mins = np.zeros((0, 4))
    sample_freq = 50
    window_size = 22
    low_acce_mag = 0.6
    step_criterion = 1
    interval_threshold = 250

    acce_max = np.zeros((2,))
    acce_min = np.zeros((2,))
    acce_binarys = np.zeros((window_size,), dtype=int)
    acce_mag_pre = 0
    state_flag = 0

    warmup_data = np.ones((window_size,)) * 9.81
    filter_b, filter_a, filter_zf = init_parameters_filter(sample_freq, warmup_data)
    acce_mag_window = np.zeros((window_size, 1))

    # detect steps according to acceleration magnitudes
    for i in np.arange(0, np.size(acce_datas, 0)):
        acce_data = acce_datas[i, :]
        acce_mag = np.sqrt(np.sum(acce_data[1:] ** 2))

        acce_mag_filt, filter_zf = signal.lfilter(filter_b, filter_a, [acce_mag], zi=filter_zf)
        acce_mag_filt = acce_mag_filt[0]

        acce_mag_window = np.append(acce_mag_window, [acce_mag_filt])
        acce_mag_window = np.delete(acce_mag_window, 0)
        mean_gravity = np.mean(acce_mag_window)
        acce_std = np.std(acce_mag_window)
        mag_threshold = np.max([low_acce_mag, 0.4 * acce_std])

        # detect valid peak or valley of acceleration magnitudes
        acce_mag_filt_detrend = acce_mag_filt - mean_gravity
        if acce_mag_filt_detrend > np.max([acce_mag_pre, mag_threshold]):
            # peak
            acce_binarys = np.append(acce_binarys, [1])
            acce_binarys = np.delete(acce_binarys, 0)
        elif acce_mag_filt_detrend < np.min([acce_mag_pre, -mag_threshold]):
            # valley
            acce_binarys = np.append(acce_binarys, [-1])
            acce_binarys = np.delete(acce_binarys, 0)
        else:
            # between peak and valley
            acce_binarys = np.append(acce_binarys, [0])
            acce_binarys = np.delete(acce_binarys, 0)

        if (acce_binarys[-1] == 0) and (acce_binarys[-2] == 1):
            if state_flag == 0:
                acce_max[:] = acce_data[0], acce_mag_filt
                state_flag = 1
            elif (state_flag == 1) and ((acce_data[0] - acce_max[0]) <= interval_threshold) and (
                    acce_mag_filt > acce_max[1]):
                acce_max[:] = acce_data[0], acce_mag_filt
            elif (state_flag == 2) and ((acce_data[0] - acce_max[0]) > interval_threshold):
                acce_max[:] = acce_data[0], acce_mag_filt
                state_flag = 1

        # choose reasonable step criterion and check if there is a valid step
        # save step acceleration data: step_acce_max_mins = [timestamp, max, min, variance]
        step_flag = False
        if step_criterion == 2:
            if (acce_binarys[-1] == -1) and ((acce_binarys[-2] == 1) or (acce_binarys[-2] == 0)):
                step_flag = True
        elif step_criterion == 3:
            if (acce_binarys[-1] == -1) and (acce_binarys[-2] == 0) and (np.sum(acce_binarys[:-2]) > 1):
                step_flag = True
        else:
            if (acce_binarys[-1] == 0) and acce_binarys[-2] == -1:
                if (state_flag == 1) and ((acce_data[0] - acce_min[0]) > interval_threshold):
                    acce_min[:] = acce_data[0], acce_mag_filt
                    state_flag = 2
                    step_flag = True
                elif (state_flag == 2) and ((acce_data[0] - acce_min[0]) <= interval_threshold) and (
                        acce_mag_filt < acce_min[1]):
                    acce_min[:] = acce_data[0], acce_mag_filt
        if step_flag:
            step_timestamps = np.append(step_timestamps, acce_data[0])
            step_indexs = np.append(step_indexs, [i])
            step_acce_max_mins = np.append(step_acce_max_mins,
                                           [[acce_data[0], acce_max[1], acce_min[1], acce_std ** 2]], axis=0)
        acce_mag_pre = acce_mag_filt_detrend

    return step_timestamps, step_indexs, step_acce_max_mins


def compute_stride_length(step_acce_max_mins):
    K = 0.4
    K_max = 0.8
    K_min = 0.4
    para_a0 = 0.21468084
    para_a1 = 0.09154517
    para_a2 = 0.02301998

    stride_lengths = np.zeros((step_acce_max_mins.shape[0], 2))
    k_real = np.zeros((step_acce_max_mins.shape[0], 2))
    step_timeperiod = np.zeros((step_acce_max_mins.shape[0] - 1, ))
    stride_lengths[:, 0] = step_acce_max_mins[:, 0]
    window_size = 2
    step_timeperiod_temp = np.zeros((0, ))

    # calculate every step period - step_timeperiod unit: second
    for i in range(0, step_timeperiod.shape[0]):
        step_timeperiod_data = (step_acce_max_mins[i + 1, 0] - step_acce_max_mins[i, 0]) / 1000
        step_timeperiod_temp = np.append(step_timeperiod_temp, [step_timeperiod_data])
        if step_timeperiod_temp.shape[0] > window_size:
            step_timeperiod_temp = np.delete(step_timeperiod_temp, [0])
        step_timeperiod[i] = np.sum(step_timeperiod_temp) / step_timeperiod_temp.shape[0]

    # calculate parameters by step period and acceleration magnitude variance
    k_real[:, 0] = step_acce_max_mins[:, 0]
    k_real[0, 1] = K
    for i in range(0, step_timeperiod.shape[0]):
        k_real[i + 1, 1] = np.max([(para_a0 + para_a1 / step_timeperiod[i] + para_a2 * step_acce_max_mins[i, 3]), K_min])
        k_real[i + 1, 1] = np.min([k_real[i + 1, 1], K_max]) * (K / K_min)

    # calculate every stride length by parameters and max and min data of acceleration magnitude
    stride_lengths[:, 1] = np.max([(step_acce_max_mins[:, 1] - step_acce_max_mins[:, 2]),
                                   np.ones((step_acce_max_mins.shape[0], ))], axis=0)**(1 / 4) * k_real[:, 1]

    return stride_lengths


def compute_headings(ahrs_datas):
    headings = np.zeros((np.size(ahrs_datas, 0), 2))
    for i in np.arange(0, np.size(ahrs_datas, 0)):
        ahrs_data = ahrs_datas[i, :]
        rot_mat = get_rotation_matrix_from_vector(ahrs_data[1:])
        azimuth, pitch, roll = get_orientation(rot_mat)
        around_z = (-azimuth) % (2 * np.pi)
        headings[i, :] = ahrs_data[0], around_z
    return headings


def compute_step_heading(step_timestamps, headings):
    step_headings = np.zeros((len(step_timestamps), 2))
    step_timestamps_index = 0
    for i in range(0, len(headings)):
        if step_timestamps_index < len(step_timestamps):
            if headings[i, 0] == step_timestamps[step_timestamps_index]:
                step_headings[step_timestamps_index, :] = headings[i, :]
                step_timestamps_index += 1
        else:
            break
    assert step_timestamps_index == len(step_timestamps)

    return step_headings


def compute_rel_positions(stride_lengths, step_headings):
    rel_positions = np.zeros((stride_lengths.shape[0], 3))
    for i in range(0, stride_lengths.shape[0]):
        rel_positions[i, 0] = stride_lengths[i, 0]
        rel_positions[i, 1] = -stride_lengths[i, 1] * np.sin(step_headings[i, 1])
        rel_positions[i, 2] = stride_lengths[i, 1] * np.cos(step_headings[i, 1])

    return rel_positions


def compute_step_positions(acce_datas, ahrs_datas, posi_datas):
    step_timestamps, step_indexs, step_acce_max_mins = compute_steps(acce_datas)
    headings = compute_headings(ahrs_datas)
    stride_lengths = compute_stride_length(step_acce_max_mins)
    step_headings = compute_step_heading(step_timestamps, headings)
    rel_positions = compute_rel_positions(stride_lengths, step_headings)
    step_positions = correct_positions(rel_positions, posi_datas)

    return step_positions

"""##Visualize_f.py"""

# this cell contains the content from visualize_f.py
from PIL import Image
import plotly as py
import random
import plotly.graph_objs as go


def save_figure_to_html(fig, filename):
    fig.write_html(filename)


def visualize_trajectory(trajectory_sum, floor_plan_filename, width_meter, height_meter, title=None, mode='lines + markers + text', show=False):
    fig = go.Figure()
    color_line_sum = []
    for trajectory in trajectory_sum:
        # add trajectory
        size_list = [6] * trajectory.shape[0]
        size_list[0] = 10
        size_list[-1] = 10

        color_list = ['rgba(4, 174, 4, 0.5)'] * trajectory.shape[0]
        color_list[0] = 'rgba(12, 5, 235, 1)'
        color_list[-1] = 'rgba(235, 5, 5, 1)'

        position_count = {}
        text_list = []
        for i in range(trajectory.shape[0]):
            if str(trajectory[i]) in position_count:
                position_count[str(trajectory[i])] += 1
            else:
                position_count[str(trajectory[i])] = 0
            text_list.append('        ' * position_count[str(trajectory[i])] + f'{i}')
        text_list[0] = 'Start'
        text_list[-1] = f'End: {trajectory.shape[0] - 1}'

        color_num1 = random.randint(0,255)
        color_num2 = random.randint(0,255)
        color_num3 = random.randint(0,255)

        while([color_num1, color_num2, color_num3] in color_line_sum):
            color_num1 = random.randint(0, 255)
            color_num2 = random.randint(0, 255)
            color_num3 = random.randint(0, 255)
        else:
            color_line_sum.append([color_num1, color_num2, color_num3])
        color_line = 'rgb({color_num1}, {color_num2}, {color_num3})'.format(color_num1 = color_num2, color_num2 = color_num2, color_num3 = color_num3)

        fig.add_trace(
            go.Scattergl(
                x=trajectory[:, 0],
                y=trajectory[:, 1],
                mode=mode,
                marker=dict(symbol = 'x',size=6, color=color_line),
                line=dict(shape='linear', color=color_line, width=2, dash='solid'),
                text=text_list,
                textposition="top center",
                name='trajectory',
            ))

        # add floor plan
        floor_plan = Image.open(floor_plan_filename)
        fig.update_layout(images=[
            go.layout.Image(
                source=floor_plan,
                xref="x",
                yref="y",
                x=0,
                y=height_meter,
                sizex=width_meter,
                sizey=height_meter,
                sizing="contain",
                opacity=1,
                layer="below",
            )
        ])

        # configure
        fig.update_xaxes(autorange=False, range=[0, width_meter])
        fig.update_yaxes(autorange=False, range=[0, height_meter], scaleanchor="x", scaleratio=1)
        fig.update_layout(
            title=go.layout.Title(
                text=title or "No title.",
                xref="paper",
                x=0,
            ),
            autosize=True,
            width=900,
            height=200 + 900 * height_meter / width_meter,
            template="plotly_white",
        )

    if show:
      fig.show()
    #py.offline.plot(fig, filename="111.html")
    return fig


def visualize_heatmap(position, value, floor_plan_filename, width_meter, height_meter, colorbar_title="colorbar", title=None, show=False):
    fig = go.Figure()

    # add heat map
    fig.add_trace(
        go.Scatter(x=position[:, 0],
                   y=position[:, 1],
                   mode='markers',
                   marker=dict(size=7,
                               color=value,
                               colorbar=dict(title=colorbar_title),
                               colorscale="Rainbow"),
                   text=value,
                   name=title))

    # add floor plan
    floor_plan = Image.open(floor_plan_filename)
    fig.update_layout(images=[
        go.layout.Image(
            source=floor_plan,
            xref="x",
            yref="y",
            x=0,
            y=height_meter,
            sizex=width_meter,
            sizey=height_meter,
            sizing="contain",
            opacity=1,
            layer="below",
        )
    ])

    # configure
    fig.update_xaxes(autorange=False, range=[0, width_meter])
    fig.update_yaxes(autorange=False, range=[0, height_meter], scaleanchor="x", scaleratio=1)
    fig.update_layout(
        title=go.layout.Title(
            text=title or "No title.",
            xref="paper",
            x=0,
        ),
        autosize=True,
        width=900,
        height=200 + 900 * height_meter / width_meter,
        template="plotly_white",
    )

    if show:
        fig.show()

    return fig

"""## Visualization of set position"""

import json
import os
from pathlib import Path
import numpy as np
def compute_step_positions(acce_datas, ahrs_datas, posi_datas):
    step_timestamps, step_indexs, step_acce_max_mins = compute_steps(acce_datas)
    headings = compute_headings(ahrs_datas)
    stride_lengths = compute_stride_length(step_acce_max_mins)
    step_headings = compute_step_heading(step_timestamps, headings)
    rel_positions = compute_rel_positions(stride_lengths, step_headings)
    step_positions = correct_positions(rel_positions, posi_datas)

    return step_positions
#Count the number of different data types in the dataset
sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']
#sites = ['site2']
#floors = ['F5']
combined_step_positions = []
waypoint_count = {}

for site in sites:
  for floor in floors:
    
    count = 0

    floor_data_dir = './data/' + site + '/' + floor
    if os.path.exists(floor_data_dir) == False:
      continue
    path_data_dir = floor_data_dir + '/path_data_files'
    floor_plan_filename = floor_data_dir + '/floor_image.png'
    floor_info_filename = floor_data_dir + '/floor_info.json'
    path_data_dir = floor_data_dir + '/path_data_files'
    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))

    with open(floor_info_filename) as f:
      floor_info = json.load(f)
    width_meter = floor_info["map_info"]["width"]
    height_meter = floor_info["map_info"]["height"]
    
    for pathfile in path_filenames:
      path_datas = read_data_file(pathfile)
      acce_datas = path_datas.acce
      magn_datas = path_datas.magn
      ahrs_datas = path_datas.ahrs
      wifi_datas = path_datas.wifi
      ibeacon_datas = path_datas.ibeacon
      posi_datas = path_datas.waypoint
      step_positions = compute_step_positions(acce_datas, ahrs_datas, posi_datas)
      combined_step_positions.append(step_positions[:, 1:3])
      #combined_step_positions = np.array(combined_step_positions)
      count += len(step_positions[:, 1:3])
      
    waypoint_count.update({site+floor:count})
    
print(waypoint_count)

import json
import os
from pathlib import Path
import numpy as np
def compute_step_positions(acce_datas, ahrs_datas, posi_datas):
    step_timestamps, step_indexs, step_acce_max_mins = compute_steps(acce_datas)
    headings = compute_headings(ahrs_datas)
    stride_lengths = compute_stride_length(step_acce_max_mins)
    step_headings = compute_step_heading(step_timestamps, headings)
    rel_positions = compute_rel_positions(stride_lengths, step_headings)
    step_positions = correct_positions(rel_positions, posi_datas)

    return step_positions
#Count the number of different data types in the dataset
sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']
#sites = ['site2']
#floors = ['F5']

waypoint_count = {}

for site in sites:
  for floor in floors:
    combined_step_positions = []  
    count = 0

    floor_data_dir = './data/' + site + '/' + floor
    if os.path.exists(floor_data_dir) == False:
      continue
    path_data_dir = floor_data_dir + '/path_data_files'
    floor_plan_filename = floor_data_dir + '/floor_image.png'
    floor_info_filename = floor_data_dir + '/floor_info.json'
    path_data_dir = floor_data_dir + '/path_data_files'
    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))

    with open(floor_info_filename) as f:
      floor_info = json.load(f)
    width_meter = floor_info["map_info"]["width"]
    height_meter = floor_info["map_info"]["height"]
    
    for pathfile in path_filenames:
      path_datas = read_data_file(pathfile)
      acce_datas = path_datas.acce
      magn_datas = path_datas.magn
      ahrs_datas = path_datas.ahrs
      wifi_datas = path_datas.wifi
      ibeacon_datas = path_datas.ibeacon
      posi_datas = path_datas.waypoint
      step_positions = compute_step_positions(acce_datas, ahrs_datas, posi_datas)
      combined_step_positions.append(step_positions[:, 1:3])
      #combined_step_positions = np.array(combined_step_positions)
      count += len(step_positions[:, 1:3])
    visualize_trajectory(combined_step_positions, floor_plan_filename, width_meter, height_meter, title='Step Position', show=True)  
    waypoint_count.update({site+floor:count})

"""##Load Site1/B1 data (Modified)"""

# this cell contains the content from main.py
import json
import os
from pathlib import Path


import numpy as np

## commented out because already included in previous cells
# from compute_f import split_ts_seq, compute_step_positions
# from io_f import read_data_file
# from visualize_f import visualize_trajectory, visualize_heatmap, save_figure_to_html

def calibrate_magnetic_wifi_ibeacon_to_position(path_file_list):
    mwi_datas = {}
    for path_filename in path_file_list:
        #print(f'Processing {path_filename}...')

        path_datas = read_data_file(path_filename)
        acce_datas = path_datas.acce
        magn_datas = path_datas.magn
        ahrs_datas = path_datas.ahrs
        wifi_datas = path_datas.wifi
        ibeacon_datas = path_datas.ibeacon
        posi_datas = path_datas.waypoint

        step_positions = compute_step_positions(acce_datas, ahrs_datas, posi_datas)
        # visualize_trajectory(posi_datas[:, 1:3], floor_plan_filename, width_meter, height_meter, title='Ground Truth', show=True)
        # visualize_trajectory(step_positions[:, 1:3], floor_plan_filename, width_meter, height_meter, title='Step Position', show=True)

        if wifi_datas.size != 0:
            sep_tss = np.unique(wifi_datas[:, 0].astype(float))
            wifi_datas_list = split_ts_seq(wifi_datas, sep_tss)
            for wifi_ds in wifi_datas_list:
                diff = np.abs(step_positions[:, 0] - float(wifi_ds[0, 0]))
                index = np.argmin(diff)
                target_xy_key = tuple(step_positions[index, 1:3])
                if target_xy_key in mwi_datas:
                    mwi_datas[target_xy_key]['wifi'] = np.append(mwi_datas[target_xy_key]['wifi'], wifi_ds, axis=0)
                else:
                    mwi_datas[target_xy_key] = {
                        'magnetic': np.zeros((0, 4)),
                        'wifi': wifi_ds,
                        'ibeacon': np.zeros((0, 3))
                    }

        if ibeacon_datas.size != 0:
            sep_tss = np.unique(ibeacon_datas[:, 0].astype(float))
            ibeacon_datas_list = split_ts_seq(ibeacon_datas, sep_tss)
            for ibeacon_ds in ibeacon_datas_list:
                diff = np.abs(step_positions[:, 0] - float(ibeacon_ds[0, 0]))
                index = np.argmin(diff)
                target_xy_key = tuple(step_positions[index, 1:3])
                if target_xy_key in mwi_datas:
                    mwi_datas[target_xy_key]['ibeacon'] = np.append(mwi_datas[target_xy_key]['ibeacon'], ibeacon_ds, axis=0)
                else:
                    mwi_datas[target_xy_key] = {
                        'magnetic': np.zeros((0, 4)),
                        'wifi': np.zeros((0, 5)),
                        'ibeacon': ibeacon_ds
                    }

        sep_tss = np.unique(magn_datas[:, 0].astype(float))
        magn_datas_list = split_ts_seq(magn_datas, sep_tss)
        for magn_ds in magn_datas_list:
            diff = np.abs(step_positions[:, 0] - float(magn_ds[0, 0]))
            index = np.argmin(diff)
            target_xy_key = tuple(step_positions[index, 1:3])
            if target_xy_key in mwi_datas:
                mwi_datas[target_xy_key]['magnetic'] = np.append(mwi_datas[target_xy_key]['magnetic'], magn_ds, axis=0)
            else:
                mwi_datas[target_xy_key] = {
                    'magnetic': magn_ds,
                    'wifi': np.zeros((0, 5)),
                    'ibeacon': np.zeros((0, 3))
                }

    return mwi_datas


def extract_magnetic_strength(mwi_datas):
    magnetic_strength = {}
    for position_key in mwi_datas:
        # print(f'Position: {position_key}')

        magnetic_data = mwi_datas[position_key]['magnetic']
        magnetic_s = np.mean(np.sqrt(np.sum(magnetic_data[:, 1:4] ** 2, axis=1)))
        magnetic_strength[position_key] = magnetic_s

    return magnetic_strength


def extract_wifi_rssi(mwi_datas):
    wifi_rssi = {}
    for position_key in mwi_datas:
        # print(f'Position: {position_key}')

        wifi_data = mwi_datas[position_key]['wifi']
        for wifi_d in wifi_data:
            bssid = wifi_d[2]
            rssi = int(wifi_d[3])

            if bssid in wifi_rssi:
                position_rssi = wifi_rssi[bssid]
                if position_key in position_rssi:
                    old_rssi = position_rssi[position_key][0]
                    old_count = position_rssi[position_key][1]
                    position_rssi[position_key][0] = (old_rssi * old_count + rssi) / (old_count + 1)
                    position_rssi[position_key][1] = old_count + 1
                else:
                    position_rssi[position_key] = np.array([rssi, 1])
            else:
                position_rssi = {}
                position_rssi[position_key] = np.array([rssi, 1])

            wifi_rssi[bssid] = position_rssi

    return wifi_rssi


def extract_ibeacon_rssi(mwi_datas):
    ibeacon_rssi = {}
    for position_key in mwi_datas:
        # print(f'Position: {position_key}')

        ibeacon_data = mwi_datas[position_key]['ibeacon']
        for ibeacon_d in ibeacon_data:
            ummid = ibeacon_d[1]
            rssi = int(ibeacon_d[2])

            if ummid in ibeacon_rssi:
                position_rssi = ibeacon_rssi[ummid]
                if position_key in position_rssi:
                    old_rssi = position_rssi[position_key][0]
                    old_count = position_rssi[position_key][1]
                    position_rssi[position_key][0] = (old_rssi * old_count + rssi) / (old_count + 1)
                    position_rssi[position_key][1] = old_count + 1
                else:
                    position_rssi[position_key] = np.array([rssi, 1])
            else:
                position_rssi = {}
                position_rssi[position_key] = np.array([rssi, 1])

            ibeacon_rssi[ummid] = position_rssi

    return ibeacon_rssi


def extract_wifi_count(mwi_datas):
    wifi_counts = {}
    for position_key in mwi_datas:
        # print(f'Position: {position_key}')

        wifi_data = mwi_datas[position_key]['wifi']
        count = np.unique(wifi_data[:, 2]).shape[0]
        wifi_counts[position_key] = count

    return wifi_counts

floor_data_dir = './data/site1/F1'
path_data_dir = floor_data_dir + '/path_data_files'
floor_plan_filename = floor_data_dir + '/floor_image.png'
floor_info_filename = floor_data_dir + '/floor_info.json'

save_dir = './output/site1/F1'
path_image_save_dir = save_dir + '/path_images'
step_position_image_save_dir = save_dir
magn_image_save_dir = save_dir
wifi_image_save_dir = save_dir + '/wifi_images'
ibeacon_image_save_dir = save_dir + '/ibeacon_images'
wifi_count_image_save_dir = save_dir

Path(path_image_save_dir).mkdir(parents=True, exist_ok=True)
Path(magn_image_save_dir).mkdir(parents=True, exist_ok=True)
Path(wifi_image_save_dir).mkdir(parents=True, exist_ok=True)
Path(ibeacon_image_save_dir).mkdir(parents=True, exist_ok=True)

with open(floor_info_filename) as f:
    floor_info = json.load(f)
width_meter = floor_info["map_info"]["width"]
height_meter = floor_info["map_info"]["height"]

path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))

"""##Exploratory Data Analysis"""

import numpy as np

def EDA_Count(data_filename):
  ACCELEROMETER_Count = 0
  ACCELEROMETER_UNCALIBRATED_Count = 0
  GYROSCOPE_Count = 0
  GYROSCOPE_UNCALIBRATED_Count = 0
  MAGNETIC_FIELD_Count = 0
  MAGNETIC_FIELD_UNCALIBRATED_Count = 0
  ROTATION_VECTOR_Count = 0
  WIFI_Count = 0
  BEACON_Count = 0
  WAYPOINT_Count = 0

  WIFI_Count_TS = 0
  BEACON_Count_TS = 0

  with open(data_filename, 'r', encoding='utf-8') as file:
      lines = file.readlines()

  for line_data in lines:
      line_data = line_data.strip()
      if not line_data or line_data[0] == '#':
          continue

      line_data = line_data.split('\t')

      if line_data[1] == 'TYPE_ACCELEROMETER':
          ACCELEROMETER_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':
          ACCELEROMETER_UNCALIBRATED_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_GYROSCOPE':
          GYROSCOPE_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_GYROSCOPE_UNCALIBRATED':
          GYROSCOPE_UNCALIBRATED_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_MAGNETIC_FIELD':
          MAGNETIC_FIELD_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_MAGNETIC_FIELD_UNCALIBRATED':
          MAGNETIC_FIELD_UNCALIBRATED_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_ROTATION_VECTOR':
          ROTATION_VECTOR_Count += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_WIFI':
          WIFI_Count += 1
          if line_data_old[0] != line_data[0]:
            WIFI_Count_TS += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_BEACON':
          BEACON_Count += 1
          if line_data_old[0] != line_data[0]:
            BEACON_Count_TS += 1
          line_data_old = line_data
          continue

      if line_data[1] == 'TYPE_WAYPOINT':
          WAYPOINT_Count += 1
          line_data_old = line_data


  Count = np.array([ACCELEROMETER_Count, ACCELEROMETER_UNCALIBRATED_Count, GYROSCOPE_Count, GYROSCOPE_UNCALIBRATED_Count, MAGNETIC_FIELD_Count, MAGNETIC_FIELD_UNCALIBRATED_Count, ROTATION_VECTOR_Count, WIFI_Count, BEACON_Count, WAYPOINT_Count])
  Count_TS = np.array([ACCELEROMETER_Count, ACCELEROMETER_UNCALIBRATED_Count, GYROSCOPE_Count, GYROSCOPE_UNCALIBRATED_Count, MAGNETIC_FIELD_Count, MAGNETIC_FIELD_UNCALIBRATED_Count, ROTATION_VECTOR_Count, WIFI_Count_TS, BEACON_Count_TS, WAYPOINT_Count])
  return Count, Count_TS

def EDA(path_file_list):
  EDA = np.zeros(10, dtype=int)
  EDA_TS = np.zeros(10, dtype=int)
  for path_filename in path_file_list:
    count, count_TS = EDA_Count(path_filename)
    EDA = EDA + count
    EDA_TS = EDA_TS + count_TS
  return EDA, EDA_TS

#Count the number of different data types in the dataset

import numpy as np
from pathlib import Path

sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']
#sites = ['site1']
#floors = ['B1']
EDA_Summary = {}
print('          '+'[ ACCEL|ACCELU|  GYRO| GYROU|   MAG|  MAGU|ROTATE|  WIFI|BEACON|WAYPNT]')

for site in sites:
  for floor in floors:
    # Dir for all sites floors
    floor_data_dir = './data/' + site + '/' + floor
    if os.path.exists(floor_data_dir) == False:
      continue
    path_data_dir = floor_data_dir + '/path_data_files'
    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))

    E, E_TS = EDA(path_filenames)
    print(site + ' ' + floor + ': ' + str(E))
    #print(site + ' ' + floor + ': ' + str(E_TS))

#Accelerometer reading plot
import numpy as np
import matplotlib.pyplot as plt

def EDA_Accel(data_filename):
  ACCEL = []
  ACCEL_UN = []

  with open(data_filename, 'r', encoding='utf-8') as file:
      lines = file.readlines()

  for line_data in lines:
      line_data = line_data.strip()
      if not line_data or line_data[0] == '#':
          continue

      line_data = line_data.split('\t')

      if line_data[1] == 'TYPE_ACCELEROMETER':
          ACCEL.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
          continue

      if line_data[1] == 'TYPE_ACCELEROMETER_UNCALIBRATED':
          ACCEL_UN.append([int(line_data[0]), float(line_data[2]), float(line_data[3]), float(line_data[4])])
          continue
  a=np.array(ACCEL)
  b=np.array(ACCEL_UN)
  return a,b

acc_, acc_un_ = EDA_Accel(path_filenames[25])

plt.plot(acc_[:,0]-acc_[0,0],acc_[:,1], c='r')
plt.plot(acc_[:,0]-acc_[0,0],acc_[:,2], c='g')
plt.plot(acc_[:,0]-acc_[0,0],acc_[:,3], c='b')
plt.legend(['x','y','z'])
plt.xlabel('Time, ms')
plt.ylabel('Acceleration, m/s^2')
plt.title('Accelerometer Reading vs Time')
plt.xlim(0,10000)
plt.show()

"""##1. visualize ground truth positions

Modified
"""

# Modified code to plot for all sites floors matplotlib. 
import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from pathlib import Path
import json

sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']

#!!run ths if want to test any floor
#sites = ['site1']
#floors = ['B1']

for site in sites:
  for floor in floors:
    # Dir for all sites floors
    floor_data_dir = './data/' + site + '/' + floor #floor_path
    if os.path.exists(floor_data_dir) == False:
      continue

    print(f'Processing {site} {floor}')

    path_data_dir = floor_data_dir + '/path_data_files' #floor_data_path
    floor_plan_filename = floor_data_dir + '/floor_image.png' #img
    floor_info_filename = floor_data_dir + '/floor_info.json'

    save_dir = './output/' + site + '/' + floor
    path_image_save_dir = save_dir + '/path_images'
    step_position_image_save_dir = save_dir

    Path(path_image_save_dir).mkdir(parents=True, exist_ok=True)

    with open(floor_info_filename) as f:
      floor_info = json.load(f)
    width_meter = floor_info["map_info"]["width"]
    height_meter = floor_info["map_info"]["height"]

    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt")) #txt_filenames

    # 1. visualize ground truth positions
    print('Visualizing ground truth positions...')
    #!!run this if wanna test this floor
    #path_filenames = path_filenames[:5]
    floor_waypoint = []
    for index, path_filename in enumerate(path_filenames):
        #print(f'Processing file: {path_filenames}...')
       # txt_path_filename = os.path.join(path_data_dir, path_filename)
        #floor_waypoint = []
        path_data = read_data_file(path_filename)
        txt_waypoint = path_data.waypoint[:, 1:3]
        floor_waypoint.append(txt_waypoint)
        
        path_id = path_filename.name.split(".")[0]
        fig_save = visualize_trajectory(floor_waypoint, floor_plan_filename, width_meter, height_meter, title=path_id, show=True)
        #png_filename = f'{path_image_save_dir}/floor_image.png'
        #png_filename = str(Path(png_filename).resolve())
        #plt.savefig(png_filename)

import matplotlib.pyplot as plt
import numpy as np
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import os

sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']

for site in sites:
  for floor in floors:
    # Dir for all sites floors
    floor_data_dir = './data/' + site + '/' + floor
    if os.path.exists(floor_data_dir) == False:
      continue

    print(f'Processing {site} {floor}')

    path_data_dir = floor_data_dir + '/path_data_files' 
    floor_plan_filename = floor_data_dir + '/floor_image.png'
    floor_info_filename = floor_data_dir + '/floor_info.json'

    save_dir = './output/' + site + '/' + floor
    path_image_save_dir = save_dir + '/path_images'
    step_position_image_save_dir = save_dir
    magn_image_save_dir = save_dir
    wifi_image_save_dir = save_dir + '/wifi_images'
    ibeacon_image_save_dir = save_dir + '/ibeacon_images'
    wifi_count_image_save_dir = save_dir

    Path(path_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(magn_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(wifi_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(ibeacon_image_save_dir).mkdir(parents=True, exist_ok=True)

    with open(floor_info_filename) as f:
      floor_info = json.load(f)
    width_meter = floor_info["map_info"]["width"]
    height_meter = floor_info["map_info"]["height"]

    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt")) 

    #enable to see all data
    #path_filenames = path_filenames[:5]
    for path_filename in path_filenames:

      #path_data = read_data_file(path_filename)
      #path_id = path_filename.name.split(".")[0]
      #fig = visualize_trajectory(path_data.waypoint[:, 1:3], floor_plan_filename, width_meter, height_meter, title=path_id, show=True)
      #html_filename = f'{path_image_save_dir}/{path_id}.html'
      #html_filename = str(Path(html_filename).resolve())
      #save_figure_to_html(fig, html_filename)

      #print(path_filenames)
      floor_waypoint = []
      path_data = read_data_file(path_filename)
      txt_waypoint = path_data.waypoint[:, 1:3]
      floor_waypoint.append(txt_waypoint)
  #    print(floor_waypoint)
  #    print(txt_waypoint)
      for i in enumerate(floor_waypoint):
        #html_filename = f'{path_image_save_dir}/{path_id}.html'
        #html_filename = str(Path(html_filename).resolve())
        for j in txt_waypoint:
          x = j[:][0]
    #      print(x)
          y = j[:][1]
          x = np.array(x)
          y = np.array(y)
          plt.plot(x, y, linewidth='0.5', linestyle='-', marker='x', markersize=3)

print('Visualizing ground truth positions...')
for path_filename in path_filenames:
    print(f'Processing file: {path_filename}...')

    path_data = read_data_file(path_filename)
    path_id = path_filename.name.split(".")[0]
    fig = visualize_trajectory(path_data.waypoint[:, 1:3], floor_plan_filename, width_meter, height_meter, title=path_id, show=True)
    html_filename = f'{path_image_save_dir}/{path_id}.html'
    html_filename = str(Path(html_filename).resolve())
    save_figure_to_html(fig, html_filename)

"""##2. visualize step position, magnetic, wifi, ibeacon"""

# 2. visualize step position, magnetic, wifi, ibeacon
# print('Visualizing more information...')
mwi_datas = calibrate_magnetic_wifi_ibeacon_to_position(path_filenames)

step_positions = np.array(list(mwi_datas.keys()))
fig = visualize_trajectory(step_positions, floor_plan_filename, width_meter, height_meter, mode='markers', title='Step Position', show=True)
html_filename = f'{step_position_image_save_dir}/step_position.html'
html_filename = str(Path(html_filename).resolve())
save_figure_to_html(fig, html_filename)

"""##Magnetic Strength"""

# Modified code to plot for all sites floors matplotlib. 
import matplotlib.pyplot as plt
import numpy as np

sites = ['site1','site2']
floors = ['B1','F1','F2','F3','F4','F5','F6','F7','F8']

for site in sites:
  for floor in floors:
    # Dir for all sites floors
    floor_data_dir = './data/' + site + '/' + floor
    if os.path.exists(floor_data_dir) == False:
      continue

    print(f'Processing {site} {floor}')

    path_data_dir = floor_data_dir + '/path_data_files'
    floor_plan_filename = floor_data_dir + '/floor_image.png'
    floor_info_filename = floor_data_dir + '/floor_info.json'

    save_dir = './output/' + site + '/' + floor
    path_image_save_dir = save_dir + '/path_images'
    step_position_image_save_dir = save_dir
    magn_image_save_dir = save_dir
    wifi_image_save_dir = save_dir + '/wifi_images'
    ibeacon_image_save_dir = save_dir + '/ibeacon_images'
    wifi_count_image_save_dir = save_dir

    Path(path_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(magn_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(wifi_image_save_dir).mkdir(parents=True, exist_ok=True)
    Path(ibeacon_image_save_dir).mkdir(parents=True, exist_ok=True)

    path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))

    # Magnetic field plot
    mwi_datas = calibrate_magnetic_wifi_ibeacon_to_position(path_filenames)

    magnetic_strength = extract_magnetic_strength(mwi_datas)
    heat_positions = np.array(list(magnetic_strength.keys()))
    heat_values = np.array(list(magnetic_strength.values()))

    x = heat_positions[:,0]
    y = heat_positions[:,1]

    png_filename = f'{magn_image_save_dir}/magnetic_strength.png'
    png_filename = str(Path(png_filename).resolve())

    fig, ax = plt.subplots()
    im = ax.scatter(x,y, c=heat_values)
    #ax.set_aspect('equal', 'box')
    ax.set_title(f'Magnetic Strength Heatmap for {site} {floor}')
    plt.colorbar(im)
    plt.savefig(png_filename)
    plt.show()

"""##Wifi RSSI

1. Run above "Import functions", "Compute_f.py", "Visualize_f.py" cells in sequence 

2. Select the site and floor then modify and run "Load Site1/B1 data".

3. Run below cells within this section to generate the 3 Wifi RSSI heatmap.
"""

def extract_wifi_rssi(mwi_datas):
    wifi_rssi = {}
    for position_key in mwi_datas:
        # print(f'Position: {position_key}')

        wifi_data = mwi_datas[position_key]['wifi']
        for wifi_d in wifi_data:
            bssid = wifi_d[2]
            rssi = int(wifi_d[3])

            if bssid in wifi_rssi:
                position_rssi = wifi_rssi[bssid]
                if position_key in position_rssi:
                    old_rssi = position_rssi[position_key][0]
                    old_count = position_rssi[position_key][1]
                    position_rssi[position_key][0] = (old_rssi * old_count + rssi) / (old_count + 1)
                    position_rssi[position_key][1] = old_count + 1
                else:
                    position_rssi[position_key] = np.array([rssi, 1])
            else:
                position_rssi = {}
                position_rssi[position_key] = np.array([rssi, 1])

            wifi_rssi[bssid] = position_rssi

    return wifi_rssi

mwi_datas = calibrate_magnetic_wifi_ibeacon_to_position(path_filenames)

wifi_rssi = extract_wifi_rssi(mwi_datas)

for target_wifi in list(wifi_rssi.keys())[0:30:10]:
  heat_positions = np.array(list(wifi_rssi[target_wifi].keys()))
  heat_values = np.array(list(wifi_rssi[target_wifi].values()))[:, 0]
  fig = visualize_heatmap(heat_positions, heat_values, floor_plan_filename, width_meter, height_meter, colorbar_title='dBm', title=f'Wifi: {target_wifi} RSSI', show=True)
  html_filename = f'{wifi_image_save_dir}/{target_wifi.replace(":", "-")}.html'
  html_filename = str(Path(html_filename).resolve())
  save_figure_to_html(fig, html_filename)

"""##iBeacon RSSI"""

#Adding ALL iBeacon points from a single floor into a heatmap
import numpy as np
import matplotlib.pyplot as plt
import json
import os
from pathlib import Path

sitefloor_list = [('site1','B1'),('site1','F1'),('site1','F2'),('site1','F3'),
                  ('site1','F4'),('site2','B1'),('site2','F1'),('site2','F2'),
                  ('site2','F3'),('site2','F4'),('site2','F5'),('site2','F6'),
                  ('site2','F7'),('site2','F8')]

for site, floor in sitefloor_list:
  sitenumber = site
  floornumber = floor
  floor_data_dir = './data/' + sitenumber + '/' + floornumber
  path_data_dir = floor_data_dir + '/path_data_files'
  path_filenames = list(Path(path_data_dir).resolve().glob("*.txt"))
  mwi_datas = calibrate_magnetic_wifi_ibeacon_to_position(path_filenames)
  step_positions = np.array(list(mwi_datas.keys()))

  ibeacon_rssi = extract_ibeacon_rssi(mwi_datas)  
  print(f'The floor {floor} of {site} has a total of {len(ibeacon_rssi.keys())} ibeacons')
  #List of ibeacon ummids 
  ibeacon_ummids_list = list(ibeacon_rssi.keys())  
  #Print the list of ibeacon ummids for the floor
  #print(ibeacon_ummids_list) 
  heat_positions = []
  heat_values = []
  #Create an iteration through the list of the ibeacon ummids
  for ummid in ibeacon_ummids_list:
    ummid = str(ummid)
    target_ibeacon = ummid  
    heat_positions_single = list(ibeacon_rssi[target_ibeacon].keys()) #List of xy coordinates
    heat_positions.extend(heat_positions_single)
    heat_values_single = np.array(list(ibeacon_rssi[target_ibeacon].values()))[:, 0] #List of RSSI values in wrt to xy coordinates
    heat_values_single = list(heat_values_single)
    heat_values.extend(heat_values_single)
  #Convert both heat_positions and heat_values back into numpy array after appending the lists for all ibeacons on the same level
  heat_positions = np.array(heat_positions)
  heat_values = np.array(heat_values)  
  #Separating the X and Y coordinates on the heat_positions numpy array
  row = len(heat_positions)
  col = heat_positions.shape[1]
  x_heat_positions = []
  y_heat_positions = []
  for a in range(row):
    x_heat_positions.append(heat_positions[a][0])
  for b in range(row):
    y_heat_positions.append(heat_positions[b][1])
  #Plot out the combined iBeacon RSSI heatmap
  width_meter = floor_info["map_info"]["width"]
  height_meter = floor_info["map_info"]["height"]
  plt.xlim = (0,width_meter)
  plt.ylim = (0, height_meter)
  plt.figure(figsize=(13,8.5)) 
  plt.scatter(x_heat_positions, y_heat_positions, c = heat_values, cmap = 'viridis')
  plt.title('iBeacon RSSI Heatmap for {} and Floor {}'.format(site,floor))
  plt.colorbar()
  plt.show()